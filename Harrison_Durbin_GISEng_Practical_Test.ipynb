{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harrison Durbin Technical Test - TomTom - 05.11.2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "import difflib as dl\n",
    "import sys\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign a value for the gap tolerance between road segments\n",
    "gap_tolerance = 30 # meters\n",
    "\n",
    "# assign a value for how closely the names of streets must match in street name chains\n",
    "name_tolerance = 97 # percent matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the shapefile\n",
    "def load_shape(sf1):\n",
    "    sf = shapefile.Reader(sf1)\n",
    "    shapes = sf.shapes()\n",
    "    records = sf.records()\n",
    "    \n",
    "    # create an array of the bounding box latitude and longitudes for each road segment\n",
    "    bbox = np.zeros(shape=(len(shapes),4))\n",
    "    for i in range(len(shapes)):\n",
    "        bbox[i] = shapes[i].bbox\n",
    "        \n",
    "    # convert bounding box latitude and longitude coordinates into meters to calculate gaps between road segments\n",
    "    coords = np.zeros(shape=(len(records),4)) # coords in meters of bounding box\n",
    "\n",
    "    for i in range(len(records)):\n",
    "        coords[i,0] = int((-bbox[i][0] - 54)*103262) # longitude converted to meters\n",
    "        coords[i,1] = int((-bbox[i][1] - 22)*110730) # latitude converted to meters\n",
    "        coords[i,2] = int((-bbox[i][2] - 54)*103262) # longitude converted to meters\n",
    "        coords[i,3] = int((-bbox[i][3] - 22)*110730) # latitude converted to meters\n",
    "        \n",
    "    \n",
    "    return records, shapes, coords\n",
    "\n",
    "# function to load csv files into python\n",
    "def iter_loadtxt(filename, delimiter=',', skiprows=0, dtype=float):\n",
    "    def iter_func():\n",
    "        \n",
    "        with open(filename, 'r') as infile:\n",
    "            for _ in range(skiprows):\n",
    "                next(infile)\n",
    "            for line in infile:\n",
    "                line = line.rstrip().split(delimiter)\n",
    "                for item in line:\n",
    "                    yield dtype(item)\n",
    "        \n",
    "        iter_loadtxt.rowlength = len(line)\n",
    "    \n",
    "    data = np.fromiter(iter_func(), dtype=dtype)\n",
    "    data = data.reshape((-1, iter_loadtxt.rowlength))\n",
    "    return data\n",
    "\n",
    "# # this code only needs to be ran once, so it is commented out\n",
    "# # create a matrix to hold the percentage matching of names for all street segments\n",
    "def create_name_matrix(records):\n",
    "    \n",
    "    name_match_matrix = np.zeros(shape=(len(records),len(records)))\n",
    "    \n",
    "    for i in range(len(records)):      \n",
    "        for j in range(len(records)):\n",
    "            s = int(100*((dl.SequenceMatcher(None, records[i][0], records[j][0])).quick_ratio()))\n",
    "            name_match_matrix[i,j]=s\n",
    "    \n",
    "    # save the name matching matrix as a csv file to load later\n",
    "    np.savetxt(\"name_matrix.csv\", name_match_matrix, fmt='%.3i',delimiter=\",\")\n",
    "    print 'Finished created name matching matrix.'    \n",
    "    \n",
    "    return name_match_matrix\n",
    "\n",
    "# # filling in distance matrix (distances from top right to lower left of different bounding boxes)\n",
    "# values are only filled in if the name matches and it is not the same road segment\n",
    "# this only needs to be done once\n",
    "def create_dist_matrix(records,name_match_matrix,coords,n):\n",
    "    \n",
    "    # # initialize a distance matrix to hold values of distances between street segments with a matching name\n",
    "    dist_matrix = np.zeros(shape=(len(shapes),len(shapes)))   \n",
    "    \n",
    "    # initially set a large value for all distances  \n",
    "    dist_matrix[:,:] = 1e8 \n",
    "\n",
    "    for i in range(len(records)):\n",
    "        for j in range(len(records)):          \n",
    "            s = name_match_matrix[i,j] # taking the name match percentage from matrix\n",
    "            if s > name_tolerance and i!=j:             \n",
    "            \n",
    "                if n == 1:\n",
    "                    dist_matrix[i,j]=abs(int(cdist([coords[i][[0,1]]],[coords[j][[2,3]]])[0])) # calculates the euclidean distance betwen segments   \n",
    "                    if i==len(records) and j==len(records):\n",
    "                        np.savetxt(\"dist_matrix1.csv\", dist_matrix, fmt='%.3i', delimiter=\",\")\n",
    "\n",
    "                if n == 2:\n",
    "                    dist_matrix[i,j]=abs(int(cdist([coords[i][[0,3]]],[coords[j][[2,1]]])[0])) # calculates the euclidean distance betwen segments \n",
    "                    if i==len(records) and j==len(records):\n",
    "                        np.savetxt(\"dist_matrix2.csv\", dist_matrix, fmt='%.3i', delimiter=\",\")\n",
    "\n",
    "                if n == 3:\n",
    "                    dist_matrix[i,j]=abs(int(cdist([coords[i][[2,3]]],[coords[j][[0,1]]])[0])) # calculates the euclidean distance betwen segments \n",
    "                    if i==len(records) and j==len(records):\n",
    "                        np.savetxt(\"dist_matrix3.csv\", dist_matrix, fmt='%.3i', delimiter=\",\")\n",
    "\n",
    "                if n == 4:                \n",
    "                    dist_matrix[i,j]=abs(int(cdist([coords[i][[2,1]]],[coords[j][[0,3]]])[0])) # calculates the euclidean distance betwen segments                \n",
    "                    if i==len(records) and j==len(records):\n",
    "                        np.savetxt(\"dist_matrix4.csv\", dist_matrix, fmt='%.3i', delimiter=\",\")\n",
    "                \n",
    "    print 'Finished created distance  matrix.'          \n",
    "    \n",
    "    return dist_matrix\n",
    "\n",
    "\n",
    "# this code compiles lists of the nodes adjacent to each side\n",
    "def link_nodes(records,name_match_matrix,fn):\n",
    "    \n",
    "    connectionsA = [] # nodes connected to the left of the node\n",
    "    connectionsB = [] # nodes connected to the left of the node\n",
    "\n",
    "    dist_matrix = iter_loadtxt(fn)\n",
    "    \n",
    "    for j in range(len(records)):\n",
    "\n",
    "        s = name_match_matrix[dist_matrix[:,j].argmin(),j]     \n",
    " \n",
    "        if min(dist_matrix[:,j]) < gap_tolerance and s > name_tolerance:\n",
    "            connectionsA.append(dist_matrix[:,j].argmin())\n",
    "        else:\n",
    "            connectionsA.append(-1) # add a value of -1 if it is not joined anything  \n",
    "    \n",
    "    for i in range(len(records)):\n",
    "        if i in connectionsA:    \n",
    "            x = connectionsA.index(i)\n",
    "            connectionsB.append(x)\n",
    "        else:\n",
    "            connectionsB.append(-1) # add a value of -1 if it is not joined anything\n",
    "#           \n",
    "            \n",
    "    return connectionsA, connectionsB\n",
    "\n",
    "            \n",
    "def find_isolated(c1,c2,c3,c4,c5,c6,c7,c8):            \n",
    "    isolated = [] # isolated nodes not joined on either side\n",
    "    for i in range(len(records)):\n",
    "        if c1[i]==-1 and c2[i]==-1 and c3[i]==-1 and c4[i]==-1 and c5[i]==-1 and c6[i]==-1 and c7[i]==-1 and c8[i]==-1:\n",
    "            isolated.append(i)\n",
    "    print 'There are ',len(isolated), 'isolated road segments.'\n",
    "    return isolated\n",
    "\n",
    "\n",
    "def find_chain(nodei,connection):\n",
    "        node = nodei\n",
    "        temp_traversed = []\n",
    "        while node != -1:          \n",
    "            node = connection[node]\n",
    "            if node != -1 and node not in temp_traversed:\n",
    "                chain.append(node)\n",
    "                temp_traversed.append(node)\n",
    "            else:\n",
    "                break\n",
    "        return chain\n",
    "\n",
    "    \n",
    "# add attributes and create new shapefile containing road_id attribute\n",
    "def create_new_shape(road_id):\n",
    "    # Read in our existing shapefile\n",
    "    r = shapefile.Reader(\"NW_test/NW_test_cleaned\")\n",
    "\n",
    "    # Create a new shapefile in memory\n",
    "    w = shapefile.Writer()\n",
    "\n",
    "    # Copy over the existing fields\n",
    "    w.fields = list(r.fields)\n",
    "\n",
    "    # Add our new field using the pyshp API\n",
    "    w.field(\"road_id\", \"C\", \"40\")\n",
    "\n",
    "    x=0\n",
    "    # Loop through each record, add a column.\n",
    "    for rec in r.records():\n",
    "        rec.append(road_id[x][0])\n",
    "        x+=1\n",
    "        # Add the modified record to the new shapefile \n",
    "        w.records.append(rec)\n",
    "\n",
    "    # Copy over the geometry without any changes\n",
    "    w._shapes.extend(r.shapes())\n",
    "\n",
    "    # Save as a new shapefile (or write over the old one)\n",
    "    w.save(\"Harrison_Durbin_GISENG_Test_Solution_REVISED\")\n",
    "    \n",
    "    return    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dist_matrix1 = create_dist_matrix(records,name_match_matrix,coords,1)\n",
    "# dist_matrix2 = create_dist_matrix(records,name_match_matrix,coords,2)\n",
    "# dist_matrix3 = create_dist_matrix(records,name_match_matrix,coords,3)\n",
    "# dist_matrix4 = create_dist_matrix(records,name_match_matrix,coords,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading shapefile.\n"
     ]
    }
   ],
   "source": [
    "records,shapes,coords = load_shape(\"NW_test/NW_test_cleaned\")\n",
    "print 'Finished loading shapefile.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading name matching matrix.\n"
     ]
    }
   ],
   "source": [
    "name_match_matrix = iter_loadtxt('name_matrix.csv') # load the name_match_matrix from the csv file\n",
    "print 'Finished loading name matching matrix.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# name_match_matrix = np.zeros(shape=(len(records),len(records)))\n",
    "# for i in range(len(records)):\n",
    "#     for j in range(len(records)):\n",
    "#         if records[i]==records[j]:\n",
    "#             name_match_matrix[i,j]=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished finding nearest road segments 1.\n"
     ]
    }
   ],
   "source": [
    "c11,c12 = link_nodes(records,name_match_matrix,'dist_matrix1.csv')\n",
    "print 'Finished finding nearest road segments 1.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished finding nearest road segments 2.\n"
     ]
    }
   ],
   "source": [
    "c21,c22 = link_nodes(records,name_match_matrix,'dist_matrix2.csv')\n",
    "print 'Finished finding nearest road segments 2.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished finding nearest road segments 3.\n"
     ]
    }
   ],
   "source": [
    "c31,c32 = link_nodes(records,name_match_matrix,'dist_matrix3.csv')\n",
    "print 'Finished finding nearest road segments 3.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished finding nearest road segments 4.\n"
     ]
    }
   ],
   "source": [
    "c41,c42 = link_nodes(records,name_match_matrix,'dist_matrix4.csv')\n",
    "print 'Finished finding nearest road segments 4.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  196 isolated road segments.\n"
     ]
    }
   ],
   "source": [
    "isolated = find_isolated(c11,c12,c21,c22,c31,c32,c41,c42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished combining street chain nodes.\n"
     ]
    }
   ],
   "source": [
    "# # creating chains of nodes and then assigning a unique road id \n",
    "x={}\n",
    "for i in range(len(records)):\n",
    "    nodei=i\n",
    "    if nodei not in isolated:         \n",
    "        chain = [] # list of nodes that are linked with current node\n",
    "        chain.append(i)    \n",
    "\n",
    "        chain1 = find_chain(nodei,c11)\n",
    "        chain2 = find_chain(nodei,c21)\n",
    "        chain3 = find_chain(nodei,c31)\n",
    "        chain4 = find_chain(nodei,c41)     \n",
    "        chain5 = find_chain(nodei,c12)\n",
    "        chain6 = find_chain(nodei,c22)\n",
    "        chain7 = find_chain(nodei,c32)\n",
    "        chain8 = find_chain(nodei,c42)  \n",
    "\n",
    "        # tabulating the unique road ids within the chain\n",
    "        chain = np.unique(chain1+chain2+chain3+chain4+chain5+chain6+chain7+chain8)\n",
    "        list(chain)\n",
    "        x[i]=chain     \n",
    "        \n",
    "print 'Finished combining street chain nodes.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished assigning road_id for non-isolated roads.\n"
     ]
    }
   ],
   "source": [
    "traversed = []\n",
    "road_id = np.zeros(shape=(len(records),1))\n",
    "road_id[:,:] = -1\n",
    "counter = 1\n",
    "\n",
    "for i in x:\n",
    "    chain = x[i]\n",
    "    chain = list(chain)\n",
    "    chain.append(i)\n",
    "\n",
    "    for j in chain:\n",
    "        if road_id[j]==-1:\n",
    "            if j not in traversed:\n",
    "                traversed.append(j)\n",
    "                road_id[j] = counter     \n",
    "\n",
    "    counter = 1+max(np.unique(road_id))\n",
    "\n",
    "print 'Finished assigning road_id for non-isolated roads.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished assigning road_id for isolated roads.\n"
     ]
    }
   ],
   "source": [
    "# assigning unique road ids for any non-linked roads\n",
    "unique_ids = np.unique(road_id)\n",
    "\n",
    "counter = 1+max(np.unique(road_id))\n",
    "\n",
    "for i in range(len(records)):        \n",
    "    if road_id[i]==-1:       \n",
    "        road_id[i]=counter\n",
    "    counter += 1\n",
    "    \n",
    "print 'Finished assigning road_id for isolated roads.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating new shapefile.\n"
     ]
    }
   ],
   "source": [
    "create_new_shape(road_id)\n",
    "print 'Finished creating new shapefile.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
